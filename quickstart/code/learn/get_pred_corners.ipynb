{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"quickstart/code/learn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage.filters as filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quickstart.code.learn.models.unet import ResNetBackbone\n",
    "from quickstart.code.learn.models.corner_models import CornerEnum\n",
    "from quickstart.code.learn.density_full import (\n",
    "    get_density_slices,\n",
    "    stack_density_slices,\n",
    "    padding_density_full,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# density_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_idx = 11\n",
    "data_path = \"quickstart/data\"\n",
    "floor_name = \"32_ShortOffice_05_F2\"\n",
    "floor_name = \"S_01_0001_1_I\"\n",
    "floor_name = \"S_29_0001_2_I\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_slices = get_density_slices(data_path, floor_name)\n",
    "_density_full = stack_density_slices(density_slices)\n",
    "_density_full = padding_density_full(_density_full)\n",
    "\n",
    "if floor_name == \"32_ShortOffice_05_F2\":\n",
    "    assert _density_full.shape == (1462, 1462, 3)\n",
    "elif floor_name == \"S_01_0001_1_I\":\n",
    "    # assert _density_full.shape == (1462, 1462, 3)\n",
    "    assert _density_full.shape == (269, 269, 3)\n",
    "elif floor_name == \"_density_full.shape\":\n",
    "    assert _density_full.shape == (627, 627, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_pred_corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding_2d(d_model, height, width):\n",
    "    \"\"\"\n",
    "    :param d_model: dimension of the model\n",
    "    :param height: height of the positions\n",
    "    :param width: width of the positions\n",
    "    :return: d_model*height*width position matrix\n",
    "    \"\"\"\n",
    "    if d_model % 4 != 0:\n",
    "        raise ValueError(\n",
    "            \"Cannot use sin/cos positional encoding with \"\n",
    "            \"odd dimension (got dim={:d})\".format(d_model)\n",
    "        )\n",
    "    pe = torch.zeros(d_model, height, width)\n",
    "    # Each dimension use half of d_model\n",
    "    d_model = int(d_model / 2)\n",
    "    div_term = torch.exp(torch.arange(0.0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "    pos_w = torch.arange(0.0, width).unsqueeze(1)\n",
    "    pos_h = torch.arange(0.0, height).unsqueeze(1)\n",
    "    pe[0:d_model:2, :, :] = (\n",
    "        torch.sin(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
    "    )\n",
    "    pe[1:d_model:2, :, :] = (\n",
    "        torch.cos(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
    "    )\n",
    "    pe[d_model::2, :, :] = (\n",
    "        torch.sin(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
    "    )\n",
    "    pe[d_model + 1 :: 2, :, :] = (\n",
    "        torch.cos(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
    "    )\n",
    "\n",
    "    return pe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_features(image_size, d_pe=128):\n",
    "    all_pe = positional_encoding_2d(d_pe, image_size, image_size)\n",
    "    pixels_x = np.arange(0, image_size)\n",
    "    pixels_y = np.arange(0, image_size)\n",
    "\n",
    "    xv, yv = np.meshgrid(pixels_x, pixels_y)\n",
    "    all_pixels = list()\n",
    "    for i in range(xv.shape[0]):\n",
    "        pixs = np.stack([xv[i], yv[i]], axis=-1)\n",
    "        all_pixels.append(pixs)\n",
    "    pixels = np.stack(all_pixels, axis=0)\n",
    "\n",
    "    pixel_features = all_pe[:, pixels[:, :, 1], pixels[:, :, 0]]\n",
    "    pixel_features = pixel_features.permute(1, 2, 0)\n",
    "    return pixels, pixel_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# corner_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corner_nms(preds, confs, image_shape):\n",
    "    data = np.zeros(image_shape)\n",
    "    neighborhood_size = 50\n",
    "    threshold = 0\n",
    "\n",
    "    for i in range(len(preds)):\n",
    "        data[preds[i, 1], preds[i, 0]] = confs[i]\n",
    "\n",
    "    data_max = filters.maximum_filter(data, neighborhood_size)\n",
    "    maxima = data == data_max\n",
    "    data_min = filters.minimum_filter(data, neighborhood_size)\n",
    "    diff = (data_max - data_min) > threshold\n",
    "    maxima[diff == 0] = 0\n",
    "\n",
    "    results = np.where(maxima > 0)\n",
    "    filtered_preds = np.stack([results[1], results[0]], axis=-1)\n",
    "\n",
    "    new_confs = list()\n",
    "    for i, pred in enumerate(filtered_preds):\n",
    "        new_confs.append(data[pred[1], pred[0]])\n",
    "    new_confs = np.array(new_confs)\n",
    "\n",
    "    return filtered_preds, new_confs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_model_path = \"../../ckpts/corner\"\n",
    "\n",
    "\n",
    "def init_corner_models(ckpt_path=\"\", floor_idx=-1):\n",
    "\n",
    "    # Load corner backbone\n",
    "    backbone = ResNetBackbone()\n",
    "    strides = backbone.strides\n",
    "    num_channels = backbone.num_channels\n",
    "    backbone = backbone.cuda()\n",
    "    backbone.eval()\n",
    "\n",
    "    # Load corner model\n",
    "    corner_model = CornerEnum(\n",
    "        input_dim=128,\n",
    "        hidden_dim=256,\n",
    "        num_feature_levels=4,\n",
    "        backbone_strides=strides,\n",
    "        backbone_num_channels=num_channels,\n",
    "    )\n",
    "    corner_model = corner_model.cuda()\n",
    "    corner_model.eval()\n",
    "\n",
    "    if not ckpt_path:\n",
    "        assert floor_idx > -1\n",
    "        ckpt_path = f\"{corner_model_path}/{floor_idx}/checkpoint.pth\"\n",
    "    ckpt = torch.load(ckpt_path, weights_only=False)\n",
    "\n",
    "    backbone_ckpt = {}\n",
    "    for key, value in ckpt[\"backbone\"].items():\n",
    "        key = key.replace(\"module.\", \"\")\n",
    "        backbone_ckpt[key] = value\n",
    "    backbone.load_state_dict(backbone_ckpt)\n",
    "\n",
    "    corner_model_ckpt = {}\n",
    "    for key, value in ckpt[\"corner_model\"].items():\n",
    "        key = key.replace(\"module.\", \"\")\n",
    "        corner_model_ckpt[key] = value\n",
    "    corner_model.load_state_dict(corner_model_ckpt)\n",
    "\n",
    "    corner_backbone = backbone\n",
    "    corner_model = corner_model\n",
    "\n",
    "    # print(\"Loaded corner models\")\n",
    "\n",
    "    return corner_backbone, corner_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_mean = [0.18115416, 0.18115416, 0.18115416]\n",
    "density_std = [0.27998772, 0.27998772, 0.27998772]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "corner_thresh = 0.5\n",
    "c_padding = 16\n",
    "side_len = 256 - c_padding * 2\n",
    "stride = side_len // 4\n",
    "ignore_border = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad the image so we get predictions near boundary\n",
    "density_full = _density_full.copy()\n",
    "\n",
    "# determine overlapping crops\n",
    "(h, w, _) = density_full.shape\n",
    "\n",
    "bboxes = []\n",
    "for i in range(int(w / stride) + 1):\n",
    "    for j in range(int(h / stride) + 1):\n",
    "        minx = i * stride\n",
    "        miny = j * stride\n",
    "        maxx = minx + side_len\n",
    "        maxy = miny + side_len\n",
    "\n",
    "        if maxy > h:\n",
    "            miny = h - side_len\n",
    "            maxy = h\n",
    "\n",
    "        if maxx > w:\n",
    "            minx = w - side_len\n",
    "            maxx = w\n",
    "\n",
    "        bbox = [minx, miny, maxx, maxy]\n",
    "        if (not len(bboxes)) or (bboxes[-1] != bbox):\n",
    "            bboxes.append(bbox)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each crop:\n",
    "# 1. run corner detector\n",
    "# 2. ignore predictions near the border\n",
    "# 3. paste onto a full floorplan result\n",
    "\n",
    "corner_full = np.zeros((h, w), dtype=np.float32)\n",
    "pixels, pixel_features = get_pixel_features(image_size=256)\n",
    "pixel_features = pixel_features.unsqueeze(0).cuda()\n",
    "\n",
    "print(\"Running corner detector on crops\")\n",
    "for minx, miny, maxx, maxy in tqdm(bboxes):\n",
    "    density_crop = density_full[miny:maxy, minx:maxx, :].copy()\n",
    "    density_crop = np.pad(\n",
    "        density_crop, [[c_padding, c_padding], [c_padding, c_padding], [0, 0]]\n",
    "    )\n",
    "    assert density_crop.shape == (256, 256, 3)\n",
    "    density_crop_512 = density_crop.copy()\n",
    "\n",
    "    density_crop = density_crop.transpose((2, 0, 1))\n",
    "    density_crop -= np.array(density_mean)[:, np.newaxis, np.newaxis]\n",
    "    density_crop /= np.array(density_std)[:, np.newaxis, np.newaxis]\n",
    "    density_crop = density_crop.astype(np.float32)\n",
    "\n",
    "    # run corner network\n",
    "    density_crop = torch.tensor(density_crop).unsqueeze(0).cuda()\n",
    "    corner_backbone, corner_model = init_corner_models(\n",
    "        ckpt_path=\"quickstart/ckpts/corner/11/checkpoint.pth\",\n",
    "        floor_idx=floor_idx,\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        image_feats, feat_mask, all_image_feats = corner_backbone(\n",
    "            density_crop\n",
    "        )  # self.corner_backbone\n",
    "        _corner_crop = corner_model(  # self.corner_model\n",
    "            image_feats, feat_mask, pixel_features, pixels, all_image_feats\n",
    "        )\n",
    "    corner_crop = _corner_crop[0].detach().cpu().numpy()\n",
    "    corner_crop = corner_crop[c_padding:-c_padding, c_padding:-c_padding]\n",
    "\n",
    "    keep_mask = np.zeros_like(corner_crop, dtype=bool)\n",
    "    keep_mask[ignore_border:-ignore_border, ignore_border:-ignore_border] = True\n",
    "    corner_crop[~keep_mask] = 0\n",
    "\n",
    "    # paste prediction in full view\n",
    "    corner_full[miny:maxy, minx:maxx] = np.maximum(\n",
    "        corner_full[miny:maxy, minx:maxx], corner_crop\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
    "for i in range(3):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(density_full[:, :, i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
    "for i in range(3):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(\n",
    "        density_crop.detach()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "        .astype(int)\n",
    "        .squeeze()\n",
    "        .transpose((1, 2, 0))[:, :, i]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [print(image_feats[f\"{i}\"].shape) for i in range(3)]\n",
    "feat_mask.shape\n",
    "# all_image_feats.keys()  # dict_keys(['layer0', 'layer1', 'layer2', 'layer3', 'layer4', 'x_original'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_mask_np = feat_mask.detach().cpu().numpy().squeeze()\n",
    "sum(feat_mask_np)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run corner_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run NMS to obtain corners in this floorplan\n",
    "(height, width) = corner_full.shape\n",
    "pixels_x = np.arange(0, width)\n",
    "pixels_y = np.arange(0, height)\n",
    "\n",
    "xv, yv = np.meshgrid(pixels_x, pixels_y)\n",
    "all_pixels = list()\n",
    "for i in range(xv.shape[0]):\n",
    "    pixs = np.stack([xv[i], yv[i]], axis=-1)\n",
    "    all_pixels.append(pixs)\n",
    "pixels_full = np.stack(all_pixels, axis=0)\n",
    "\n",
    "corner_thresh = 0.00001\n",
    "pos_indices = np.where(corner_full >= corner_thresh)\n",
    "pred_corners = pixels_full[pos_indices]\n",
    "pred_confs = corner_full[pos_indices]\n",
    "pred_corners, pred_confs = corner_nms(  # my_utils.corner_nms\n",
    "    pred_corners, pred_confs, image_shape=corner_full.shape\n",
    ")\n",
    "print(len(pred_corners))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"quickstart/data/pred_corners/{floor_name}.npy\", pred_corners)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove padding from pixel coordinates\n",
    "# density_full = density_full[pad_border:-pad_border, pad_border:-pad_border]\n",
    "# corner_full = corner_full[pad_border:-pad_border, pad_border:-pad_border]\n",
    "# pred_corners -= pad_border\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(density_full[:, :, 1], cmap=\"gray\")\n",
    "plt.imshow(\n",
    "    corner_full,\n",
    "    cmap=\"hot\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "plt.plot(pred_corners[:, 0], pred_corners[:, 1], \"*c\")\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
